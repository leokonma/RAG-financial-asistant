# ================================================================
# query_finance_rag.py ‚Äî RAG using OpenAI GPT-3.5 + OpenAI Embeddings
# ================================================================

import os
from dotenv import load_dotenv

load_dotenv()

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import ChatPromptTemplate

CHROMA_DIR = "data/chroma_finance_db"

# --- Load Embeddings ---
print("üîµ Loading Chroma DB with OpenAI embeddings...")
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

vectorstore = Chroma(
    persist_directory=CHROMA_DIR,
    embedding_function=embeddings
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# --- Load LLM ---
print("ü§ñ Loading LLM: gpt-3.5-turbo")
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.15,
    max_tokens=350
)

# --- Build Prompt Template ---
prompt = ChatPromptTemplate.from_messages([
    ("system", """
Eres un asistente experto en an√°lisis de finanzas personales.

Reglas:
- Usa SOLO el contexto recuperado del vector DB.
- Calcula montos, totales, promedios, meses, trimestres y categor√≠as.
- Si falta informaci√≥n, dilo expl√≠citamente.
- S√© preciso y profesional.
"""),
    ("user", "{question}"),
    ("system", "Contexto recuperado:\n{context}")
])

# --- RAG chain ---
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt}
)

print("\nüí¨ Personal Finance RAG (OpenAI GPT-3.5) ready.\n")

# --- Loop ---
while True:
    q = input("üß† Ask about your finances: ")

    if q.lower() in ["exit", "quit"]:
        print("üëã Bye!")
        break

    try:
        result = qa.invoke({"query": q})
        print(f"üí° {result['result']}\n")
    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}\n")
