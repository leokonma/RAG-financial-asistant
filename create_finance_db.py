# ================================================================
# create_finance_db.py â€” ConversiÃ³n de transacciones a embeddings
# ================================================================

import os
import torch
from time import sleep

# ğŸš« Desactivar telemetrÃ­a y avisos de Chroma
os.environ["ANONYMIZED_TELEMETRY"] = "false"
os.environ["CHROMA_TELEMETRY_ENABLED"] = "false"

# === LibrerÃ­as de LangChain ===
from langchain_community.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# âœ… Compatibilidad entre versiones (sin cambiar requirements)
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings

from langchain_chroma import Chroma

# === ParÃ¡metros ===
CSV_PATH = "data/Personal_Finance_Dataset.csv"
CHROMA_DIR = "data/chroma_finance_db"

# === Paso 1: Cargar datos ===
print("âœ… Loading transactions from CSV...")
loader = CSVLoader(file_path=CSV_PATH, encoding="utf-8")
docs = loader.load()
print(f"âœ… Loaded {len(docs)} transactions.")

# === Paso 2: Dividir texto ===
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
texts = splitter.split_documents(docs)
print(f"âœ… Generated {len(texts)} text chunks.")

# === Paso 3: Cargar modelo de embeddings ===
print("âš™ï¸ Loading model... this may take a few minutes â³")
torch.set_num_threads(4)  # evita bloqueos al inicializar PyTorch

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

print("âœ… Embedding model loaded successfully.")

# === Paso 4: Crear base vectorial ===
print("ğŸ’¾ Creating Chroma vector database...")
vector_store = Chroma.from_documents(
    documents=texts,
    embedding=embeddings,
    persist_directory=CHROMA_DIR
)

print(f"âœ… Stored {len(texts)} chunks in {CHROMA_DIR}")
print("ğŸš€ Finance DB successfully created and persisted.")
print("ğŸ¯ You can now run `python query_finance_rag.py` to query your finance data.")
